{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"images/python-logo-master.png\" style=\"width:252px\"></td>\n",
    "<td><img src=\"images/pandas_logo.png\" style=\"width:525px\"></td>\n",
    "</tr>\n",
    "</table>             \n",
    "\n",
    "# Data Manipulation with Python and Pandas\n",
    "\n",
    "## School of Medicine Research Computing\n",
    "**Christina Gancayco**<br>\n",
    "**January 15, 2019**<br>\n",
    "**gancayco@virginia.edu**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Can You Do With Pandas?\n",
    "* Data cleansing and preparation\n",
    "* Data analysis and modeling\n",
    "* Read data from many different file types (e.g. CSV, Excel, text file, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "<p>\n",
    "In this workshop we will manipulate survey data from the National Health and Nutrition Examination Survey conducted by the CDC. We will work with this dataset throughout the entire tutorial. Answers to example questions can be found in the notebook at this link: .\n",
    "</p>\n",
    "\n",
    "1. Importing pandas\n",
    "2. Reading a dataset into Python\n",
    "3. Properties of a DataFrame\n",
    "4. Preliminary analysis\n",
    "5. Pandas Operations\n",
    "    * Query\n",
    "    * Quantile\n",
    "    * Select and drop\n",
    "    * Sort values\n",
    "    * Assign\n",
    "    * Group by\n",
    "    * Aggregate\n",
    "6. \"Piping\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Importing Pandas\n",
    "<p>\n",
    "Before we can begin using Pandas, we first have to import the module. We will be importing Pandas as `pd` for short.\n",
    "<br>\n",
    "<br>\n",
    "We will be using Numpy later in the workshop, so we can go ahead and import that now as well. Go ahead and run the cell block below by selecting it and clicking the \"Run\" button in the menu above or hitting the `Shift`+`Return` keys at the same time.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Hashes are used to comment code\n",
    "# Anything following a hash is not executed\n",
    "# Comments are awesome for annotating code!\n",
    "\n",
    "# Let's import the modules we'll be using\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading a dataset into Python\n",
    "<p>\n",
    "Pandas can read data from a variety of file types. The commands to read in data start with `read_`.\n",
    "<br>\n",
    "<br>\n",
    "In this case we will be reading in data from a CSV file `nhanes.csv`, so we will use Pandas' `read_csv` command.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to read the data from nhanes.csv.\n",
    "\n",
    "# We will assign the input data to a variable called df.\n",
    "# (In this lesson we are using df, but you can name this variable anything you want.)\n",
    "\n",
    "df = pd.read_csv(\"nhanes.csv\")\n",
    "\n",
    "\n",
    "# Let's also check out the data type of df\n",
    "\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataFrames\n",
    "<p>\n",
    "From the previous cell, we can see that `df` is a DataFrame.\n",
    "<br>\n",
    "<br>\n",
    "<b>DataFrames</b> are 2-D tabular data structures with labeled columns and rows. Typically each row corresponds to a single observation or case of multiple measurements (represented by columns). The table below is an example representation of a DataFrame.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Index</th> <th>id</th> <th>Gender</th> <th>Age</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td> <td>62163</td> <td>male</td> <td>14</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td> <td>62172</td> <td>female</td> <td>43</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>2</td> <td>62174</td> <td>male</td> <td>80</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>3</td> <td>62174</td> <td>male</td> <td>80</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>4</td> <td>62175</td> <td>male</td> <td>5</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "In this case, `Index` is the label for the DataFrame's rows, and `id`, `Gender`, and `Age` are the column labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Properties of DataFrames\n",
    "\n",
    "<p>\n",
    "Usually the DataFrames we work with have a lot more than 5 rows and 3 columns, so it can be more difficult to visually inspect our DataFrame. There are several attributes we can explore to learn more about our DataFrame.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th><p style=\"font-size:12pt\">Attribute</p></th> <th><p style=\"font-size:12pt\">Output</p></th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p style=\"font-size:12pt\">`shape`</p></td> <td><p style=\"font-size:12pt\">Dimensions of DataFrame <br>(# rows, # columns)</p></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p style=\"font-size:12pt\">`index`</p></td> <td><p style=\"font-size:12pt\">Row label range <br>(`Index` min and max)</p></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p style=\"font-size:12pt\">`columns`</p></td> <td><p style=\"font-size:12pt\">Column labels <br> (e.g. `id`, `Gender`, `Age`)</p></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Use of these methods is demonstrated in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Display the shape of the DataFrame assigned to the variable df\n",
    "print(\"Shape of df is:\", df.shape)\n",
    "\n",
    "# Display the row label range of df\n",
    "print(\"df row labels:\", df.index)\n",
    "\n",
    "# Display the column labels of df\n",
    "print(\"df column labels:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preliminary Analysis\n",
    "\n",
    "<p>\n",
    "We can use a few different methods to preview the contents of the dataset.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th><p style=\"font-size:12pt\">Method</p></th> <th><p style=\"font-size:12pt\">Output</p></th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p style=\"font-size:12pt\">`head(n)`</p></td> <td><p style=\"font-size:12pt\">Display first `n` rows of DataFrame<br>(default n=5)</p></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p style=\"font-size:12pt\">`tail(n)`</p></td> <td><p style=\"font-size:12pt\">Display last `n` rows of DataFrame<br>(default n=5)</p></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p style=\"font-size:12pt\">`describe()`</p></td> <td><p style=\"font-size:12pt\">Display summary stats for each column</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Using head, we can view the first five rows of the dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also view the first ten rows if we set n equal to 10.\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# tail works similarly, but instead displays the last n rows.\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# With describe, we can calculate and view preliminary statistics including mean, standard deviation, etc.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pandas Operations\n",
    "\n",
    "There are a variety of way we can manipulate the data using Pandas operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Query\n",
    "\n",
    "The `query` operation is used to filter your data according to some criteria.\n",
    "\n",
    "For example, we can return all the rows in our dataframe where the column variable `SmokingStatus` is `Never`.\n",
    "\n",
    "There are several ways we can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Query Method 1\n",
    "\n",
    "# The following line of code will return a vector of booleans telling us which rows\n",
    "# contain a value of \"Never\" in the SmokingStatus column\n",
    "\n",
    "print(df.SmokingStatus == \"Never\")\n",
    "\n",
    "# We can use those booleans to index our dataframe\n",
    "\n",
    "df[df.SmokingStatus == \"Never\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*Side Note\n",
    "\n",
    "When we index or query our dataframe, we are not overwriting are original dataframe with our filtered result.\n",
    "\n",
    "In order to save any changes made to your dataframe you must either overwrite your current dataframe or store it in a new variable.\n",
    "\n",
    "eg. `NonSmokers = df[df.SmokingStatus==\"Never\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Query Method 2\n",
    "\n",
    "# Here we are using pandas' query method to filter our dataframe. Again we are looking for\n",
    "# all the rows in our dataframe that have a value of \"Never\" in the SmokingStatus column\n",
    "\n",
    "df.query(\"SmokingStatus == 'Never'\")\n",
    "\n",
    "# Note that the input argument to query is a string (e.g \"SmokingStatus == 'Never'\")\n",
    "# Since \"Never\" is also a string, we need to use single quotes to differentiate it from within the larger string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## More Fun with Query\n",
    "\n",
    "# We can query with numbers in addition to strings\n",
    "\n",
    "df[df.BPSys >= 130]\n",
    "\n",
    "df.query(\"Age < 18\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Query with Logical Operators\n",
    "\n",
    "# We can also use logical operators like AND (&) and OR (|) when we query.\n",
    "\n",
    "# Here we want to return rows of our data frame that have a value of \"Never\"\n",
    "# in the SmokingStatus column AND a value greater than 130 in the BPSys column\n",
    "\n",
    "df[(df.SmokingStatus == \"Never\") & (df.BPSys > 130)]\n",
    "\n",
    "# When we index our dataframe with logical operators we want to separate conditions with parentheses\n",
    "# However, if we use pandas' query method, we just put everything in a single string argument.\n",
    "\n",
    "df.query(\"SmokingStatus == 'Never' & BPSys > 130\")\n",
    "\n",
    "# Here we want to return rows of our dataframe that have a value\n",
    "# of \"Never\" OR \"Former\" in the SmokingStatus column\n",
    "\n",
    "df[(df.SmokingStatus == \"Never\") | (df.SmokingStatus == \"Former\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Example 1\n",
    "Query for current smokers with a BMI over 25.\n",
    "\n",
    "The result should be 394 rows x 32 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 1\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile\n",
    "\n",
    "The `quantile` operation can be used to determine the quantiles or percentiles for columns in your dataframe with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we are determining the 50th percentile (or median) for income.\n",
    "\n",
    "df.Income.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can then use that value to index our dataframe for rows containing\n",
    "# an Income value greater than our 50th percentile, 50000.\n",
    "\n",
    "df[df.Income > 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can combine the two lines above into a single line of code.\n",
    "\n",
    "df[df.Income > df.Income.quantile(0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2\n",
    "\n",
    "Find the patients who are in the 90th percentile for BMI.\n",
    "\n",
    "The result should be 481 rows x 32 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 2\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Drop\n",
    "\n",
    "If you only need to work with certain variables, you can select or drop columns of your dataframe until it contains only the variables of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting data\n",
    "\n",
    "# To select columns you want to keep, use two sets of brackets [[]].\n",
    "\n",
    "# If we only want the \"Age\" column, then we can use the following line of code:\n",
    "\n",
    "df[[\"Age\"]]\n",
    "\n",
    "# If we want to keep multiple columns, we can use the same syntax and\n",
    "# separate items with a comma.\n",
    "\n",
    "df[[\"Gender\", \"Age\", \"Race\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping (removing) data\n",
    "\n",
    "# To drop individual columns, we can use the \"drop\" operation\n",
    "\n",
    "df.drop(\"id\", axis=1)\n",
    "\n",
    "# We need to specify the axis (0=rows (default), 1=columns), or else drop doesn't work.\n",
    "\n",
    "# We can drop multiple columns at once by putting the column names in a list.\n",
    "\n",
    "df.drop([\"id\", \"Insured\", \"Poverty\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Values\n",
    "\n",
    "We can sort the rows of our dataframe by the values of any variable by using the `sort_values` operation. For example, we can sort them by age, so that the youngest patients appear at the top of the dataframe and the oldest appear at the bottom. We could also sort them in descending order if we want the oldest at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe by using \"sort_values\" and setting the \"by\" input argument to your desired variable.\n",
    "\n",
    "df.sort_values(by=\"Age\")\n",
    "\n",
    "# We can sort in descending order\n",
    "df.sort_values(by=\"Age\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*Combining Operations\n",
    "\n",
    "We can combine operations by stringing them together. The below example shows how we can select desired columns and sort the rows in the same line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining operations\n",
    "\n",
    "df[[\"Gender\", \"Age\", \"Race\"]].sort_values(by=\"Race\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3\n",
    "\n",
    "Select the `id`, `Weight`, `Height`, and `BMI` columns from the dataframe and sort by `BMI` in descending order.\n",
    "\n",
    "The result should be 5000 rows x 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 3\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign\n",
    "\n",
    "We can use the `assign` operation to add new column variables to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign\n",
    "\n",
    "# Let's create a new dataframe to play with containing only the Weight and Height columns.\n",
    "\n",
    "myDF = df[[\"Weight\", \"Height\"]]\n",
    "\n",
    "# The weight and height are listed in metric units of measurement.\n",
    "# Let's convert the weight from kilograms to pounds and assign the result as a new\n",
    "# variable in the dataframe myDF.\n",
    "\n",
    "myDF.assign(WeightLB = myDF.Weight*2.2)\n",
    "\n",
    "# Here we multiplied the values in the weight column by 2.2 to convert from kg to lb\n",
    "# and assigned the result to a column called WeightLB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*Side Note\n",
    "\n",
    "As was shown with the `query` operation, in order to save any changes made to your dataframe you must either overwrite your current dataframe or store it in a new variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by\n",
    "\n",
    "The `groupby` operation allows you to split your data into groups, apply a function to each of those groups independently, and combine the results into a data structure.\n",
    "\n",
    "In the example below, the dataframe is split into groups based on the different `SmokingStatus` types, and various summary statistics are performed on each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by\n",
    "\n",
    "# The groupby operation splits the data into the separate SmokingStatus types.\n",
    "# This merely performs the splitting into groups.\n",
    "\n",
    "SmokingGroups = df.groupby(\"SmokingStatus\")\n",
    "\n",
    "# We can use the describe function that we used previously to display \n",
    "# summary statistics for each column variable within each SmokingStatus group\n",
    "\n",
    "SmokingGroups.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by (individual variables and statistics)\n",
    "\n",
    "# If we only need to look at the summary statistics for one variable, we can specify that.\n",
    "# In the example below, we want to look at the summary statistics for Weight within each SmokingStatus group.\n",
    "\n",
    "SmokingGroups = df.groupby(\"SmokingStatus\")\n",
    "SmokingGroups[\"Weight\"].describe()\n",
    "\n",
    "# We can also look at individual stats.\n",
    "SmokingGroups[\"Weight\"].mean()\n",
    "SmokingGroups[\"Weight\"].quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate\n",
    "\n",
    "Using the aggregate function on a grouped dataframe allows us to perform additional computations on the grouped data, such as functions from the Numpy (`np`) package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate\n",
    "\n",
    "SmokingGroups = df.groupby(\"SmokingStatus\")\n",
    "\n",
    "# Calculate the mean using Numpy's mean function\n",
    "SmokingGroups.agg(np.mean)\n",
    "\n",
    "# You can apply multiple aggregate functions at once by putting the functions in a list\n",
    "SmokingGroups[\"Weight\"].agg([np.mean, np.median, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4\n",
    "\n",
    "Determine the median `Income` for the different `Education` groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 4\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a dataframe to a CSV file\n",
    "\n",
    "If you want to write a new or modified dataframe to a CSV file, you can use the `to_csv` function.\n",
    "\n",
    "In the example below we are writing the dataframe `myDF` to the CSV file called `output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a dataframe to a CSV file\n",
    "\n",
    "myDF.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Examples\n",
    "\n",
    "Below are a few more examples to try on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5\n",
    "\n",
    "Query the dataframe for female patients who are 18 years old and older. Sort by `Pulse` in descending order adn view the first 10 rows. You can use the `query` -> `sort_values` -> `head` functions.\n",
    "\n",
    "The result should be 10 rows x 33 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 5\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6\n",
    "\n",
    "Group by race and display summary statistics for systolic blood pressure (column name `BPSys`). You can use the `groupby` -> `describe` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 6\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7\n",
    "\n",
    "Select the `id`, `Education`, `PhysActive`, and `PhysActiveDays` columns. Calculate the percentage of physically active days and assign it to a new variable called `PCTActive` (calculate by dividing `PhysActiveDays` by 7 and multiplying by 100). Sort in ascending order by `PCTActive` and display the first 10 rows. You can use `[[\"col1\", \"col2\", ...]]` -> `assign` -> `query` -> `sort_values` -> `head`.\n",
    "\n",
    "The result should be 10 rows x 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 7\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8\n",
    "\n",
    "Query the dataframe for patients with `Income` below the 50th percentile. Group by `Race` and show the mean `Weight`. You can use `query` -> `groupby` -> `aggregate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 8\n",
    "\n",
    "#---Your code here---#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9\n",
    "\n",
    "Group by `Education` and calculate mean hours of sleep (use column `SleepHrsNight`). Sort by `SleepHrsNight` in descending order. You can use `groupby` -> `agg` -> `sort_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 9\n",
    "\n",
    "#---Your code here---#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
